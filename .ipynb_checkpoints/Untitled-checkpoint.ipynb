{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/files/audio.raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e6874755a68d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Loads the audio into memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecognitionAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/files/audio.raw'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import speech_recognition as sr\n",
    "\n",
    "#Find & Read in all stores in destiny USA\n",
    "#data = pd.read_html('https://www.syracuse.com/destiny-usa/index.ssf/2014/07/destiny_usa_hours_syracuse_mall_stores_restaurants_entertainment_directory.html')\n",
    "#data.head()\n",
    "\n",
    "#https://pythonspot.com/speech-recognition-using-google-speech-api/\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "#print(dir(speech))\n",
    "#print(help(speech.SpeechClient))\n",
    "#GOOGLE_APPLICATION_CREDENTIALS = \"/home/user/Desktop/IST256-edc7c4bfecba (1).json\"\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "file_name = os.path.join(\n",
    "   os.path.dirname('/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/Digimall-Bot'),\n",
    "   'files',\n",
    "   'audio.raw')\n",
    "\n",
    "# Loads the audio into memory\n",
    "with io.open(file_name, 'rb') as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code='en-US')\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config, audio)\n",
    "\n",
    "for result in response.results:\n",
    "    print('Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "\n",
    "#https://cloud.google.com/text-to-speech/docs/quickstart-client-libraries#client-libraries-install-python\n",
    "#https://www.yelp.com/developers/graphql/guides/intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SpeechClient', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'absolute_import', 'enums', 'types']\n",
      "Help on class SpeechClient in module google.cloud.speech_v1:\n",
      "\n",
      "class SpeechClient(google.cloud.speech_v1.helpers.SpeechHelpers, google.cloud.speech_v1.gapic.speech_client.SpeechClient)\n",
      " |  Service that implements Google Cloud Speech API.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SpeechClient\n",
      " |      google.cloud.speech_v1.helpers.SpeechHelpers\n",
      " |      google.cloud.speech_v1.gapic.speech_client.SpeechClient\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  enums = <module 'google.cloud.speech_v1.gapic.enums' fro...-packages/g...\n",
      " |  \n",
      " |  types = <module 'google.cloud.speech_v1.types' from '/Li...6/site-pack...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.cloud.speech_v1.helpers.SpeechHelpers:\n",
      " |  \n",
      " |  streaming_recognize(self, config, requests, retry=<object object at 0x101dc2e30>, timeout=<object object at 0x101dc2e30>)\n",
      " |      Perform bi-directional speech recognition.\n",
      " |      \n",
      " |      This method allows you to receive results while sending audio;\n",
      " |      it is only available via. gRPC (not REST).\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          This method is EXPERIMENTAL. Its interface might change in the\n",
      " |          future.\n",
      " |      \n",
      " |      Example:\n",
      " |        >>> from google.cloud.speech_v1 import enums\n",
      " |        >>> from google.cloud.speech_v1 import SpeechClient\n",
      " |        >>> from google.cloud.speech_v1 import types\n",
      " |        >>> client = SpeechClient()\n",
      " |        >>> config = types.StreamingRecognitionConfig(\n",
      " |        ...     config=types.RecognitionConfig(\n",
      " |        ...         encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
      " |        ...     ),\n",
      " |        ... )\n",
      " |        >>> request = types.StreamingRecognizeRequest(audio_content=b'...')\n",
      " |        >>> requests = [request]\n",
      " |        >>> for element in client.streaming_recognize(config, requests):\n",
      " |        ...     # process element\n",
      " |        ...     pass\n",
      " |      \n",
      " |      Args:\n",
      " |          config (:class:`~.types.StreamingRecognitionConfig`): The\n",
      " |              configuration to use for the stream.\n",
      " |          requests (Iterable[:class:`~.types.StreamingRecognizeRequest`]):\n",
      " |              The input objects.\n",
      " |          retry (Optional[google.api_core.retry.Retry]):  A retry object used\n",
      " |              to retry requests. If ``None`` is specified, requests will not\n",
      " |              be retried.\n",
      " |          timeout (Optional[float]): The amount of time, in seconds, to wait\n",
      " |              for the request to complete. Note that if ``retry`` is\n",
      " |              specified, the timeout applies to each individual attempt.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Iterable[:class:`~.types.StreamingRecognizeResponse`]\n",
      " |      \n",
      " |      Raises:\n",
      " |        :exc:`google.gax.errors.GaxError` if the RPC is aborted.\n",
      " |        :exc:`ValueError` if the parameters are invalid.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from google.cloud.speech_v1.helpers.SpeechHelpers:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.cloud.speech_v1.gapic.speech_client.SpeechClient:\n",
      " |  \n",
      " |  __init__(self, transport=None, channel=None, credentials=None, client_config={'interfaces': {'google.cloud.speech.v1.Speech': {'retry_codes': {'idempotent': ['DEADLINE_EXCEEDED', 'UNAVAILABLE'], 'non_idempotent': []}, 'retry_params': {'default': {'initial_retry_delay_millis': 100, 'retry_delay_multiplier': 1.3, 'max_retry_delay_millis': 60000, 'initial_rpc_timeout_millis': 1000000, 'rpc_timeout_multiplier': 1.0, 'max_rpc_timeout_millis': 1000000, 'total_timeout_millis': 5000000}}, 'methods': {'Recognize': {'timeout_millis': 1000000, 'retry_codes_name': 'idempotent', 'retry_params_name': 'default'}, 'LongRunningRecognize': {'timeout_millis': 60000, 'retry_codes_name': 'non_idempotent', 'retry_params_name': 'default'}, 'StreamingRecognize': {'timeout_millis': 1000000, 'retry_codes_name': 'idempotent', 'retry_params_name': 'default'}}}}}, client_info=None)\n",
      " |      Constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |          transport (Union[~.SpeechGrpcTransport,\n",
      " |                  Callable[[~.Credentials, type], ~.SpeechGrpcTransport]): A transport\n",
      " |              instance, responsible for actually making the API calls.\n",
      " |              The default transport uses the gRPC protocol.\n",
      " |              This argument may also be a callable which returns a\n",
      " |              transport instance. Callables will be sent the credentials\n",
      " |              as the first argument and the default transport class as\n",
      " |              the second argument.\n",
      " |          channel (grpc.Channel): DEPRECATED. A ``Channel`` instance\n",
      " |              through which to make calls. This argument is mutually exclusive\n",
      " |              with ``credentials``; providing both will raise an exception.\n",
      " |          credentials (google.auth.credentials.Credentials): The\n",
      " |              authorization credentials to attach to requests. These\n",
      " |              credentials identify this application to the service. If none\n",
      " |              are specified, the client will attempt to ascertain the\n",
      " |              credentials from the environment.\n",
      " |              This argument is mutually exclusive with providing a\n",
      " |              transport instance to ``transport``; doing so will raise\n",
      " |              an exception.\n",
      " |          client_config (dict): DEPRECATED. A dictionary of call options for\n",
      " |              each method. If not specified, the default configuration is used.\n",
      " |          client_info (google.api_core.gapic_v1.client_info.ClientInfo):\n",
      " |              The client info used to send a user-agent string along with\n",
      " |              API requests. If ``None``, then default info will be used.\n",
      " |              Generally, you only need to set this if you're developing\n",
      " |              your own client library.\n",
      " |  \n",
      " |  long_running_recognize(self, config, audio, retry=<object object at 0x101dc2e30>, timeout=<object object at 0x101dc2e30>, metadata=None)\n",
      " |      Performs asynchronous speech recognition: receive results via the\n",
      " |      google.longrunning.Operations interface. Returns either an\n",
      " |      ``Operation.error`` or an ``Operation.response`` which contains\n",
      " |      a ``LongRunningRecognizeResponse`` message.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> from google.cloud import speech_v1\n",
      " |          >>> from google.cloud.speech_v1 import enums\n",
      " |          >>>\n",
      " |          >>> client = speech_v1.SpeechClient()\n",
      " |          >>>\n",
      " |          >>> encoding = enums.RecognitionConfig.AudioEncoding.FLAC\n",
      " |          >>> sample_rate_hertz = 44100\n",
      " |          >>> language_code = 'en-US'\n",
      " |          >>> config = {'encoding': encoding, 'sample_rate_hertz': sample_rate_hertz, 'language_code': language_code}\n",
      " |          >>> uri = 'gs://bucket_name/file_name.flac'\n",
      " |          >>> audio = {'uri': uri}\n",
      " |          >>>\n",
      " |          >>> response = client.long_running_recognize(config, audio)\n",
      " |          >>>\n",
      " |          >>> def callback(operation_future):\n",
      " |          ...     # Handle result.\n",
      " |          ...     result = operation_future.result()\n",
      " |          >>>\n",
      " |          >>> response.add_done_callback(callback)\n",
      " |          >>>\n",
      " |          >>> # Handle metadata.\n",
      " |          >>> metadata = response.metadata()\n",
      " |      \n",
      " |      Args:\n",
      " |          config (Union[dict, ~google.cloud.speech_v1.types.RecognitionConfig]): *Required* Provides information to the recognizer that specifies how to\n",
      " |              process the request.\n",
      " |              If a dict is provided, it must be of the same form as the protobuf\n",
      " |              message :class:`~google.cloud.speech_v1.types.RecognitionConfig`\n",
      " |          audio (Union[dict, ~google.cloud.speech_v1.types.RecognitionAudio]): *Required* The audio data to be recognized.\n",
      " |              If a dict is provided, it must be of the same form as the protobuf\n",
      " |              message :class:`~google.cloud.speech_v1.types.RecognitionAudio`\n",
      " |          retry (Optional[google.api_core.retry.Retry]):  A retry object used\n",
      " |              to retry requests. If ``None`` is specified, requests will not\n",
      " |              be retried.\n",
      " |          timeout (Optional[float]): The amount of time, in seconds, to wait\n",
      " |              for the request to complete. Note that if ``retry`` is\n",
      " |              specified, the timeout applies to each individual attempt.\n",
      " |          metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n",
      " |              that is provided to the method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A :class:`~google.cloud.speech_v1.types._OperationFuture` instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          google.api_core.exceptions.GoogleAPICallError: If the request\n",
      " |                  failed for any reason.\n",
      " |          google.api_core.exceptions.RetryError: If the request failed due\n",
      " |                  to a retryable error and retry attempts failed.\n",
      " |          ValueError: If the parameters are invalid.\n",
      " |  \n",
      " |  recognize(self, config, audio, retry=<object object at 0x101dc2e30>, timeout=<object object at 0x101dc2e30>, metadata=None)\n",
      " |      Performs synchronous speech recognition: receive results after all audio\n",
      " |      has been sent and processed.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> from google.cloud import speech_v1\n",
      " |          >>> from google.cloud.speech_v1 import enums\n",
      " |          >>>\n",
      " |          >>> client = speech_v1.SpeechClient()\n",
      " |          >>>\n",
      " |          >>> encoding = enums.RecognitionConfig.AudioEncoding.FLAC\n",
      " |          >>> sample_rate_hertz = 44100\n",
      " |          >>> language_code = 'en-US'\n",
      " |          >>> config = {'encoding': encoding, 'sample_rate_hertz': sample_rate_hertz, 'language_code': language_code}\n",
      " |          >>> uri = 'gs://bucket_name/file_name.flac'\n",
      " |          >>> audio = {'uri': uri}\n",
      " |          >>>\n",
      " |          >>> response = client.recognize(config, audio)\n",
      " |      \n",
      " |      Args:\n",
      " |          config (Union[dict, ~google.cloud.speech_v1.types.RecognitionConfig]): *Required* Provides information to the recognizer that specifies how to\n",
      " |              process the request.\n",
      " |              If a dict is provided, it must be of the same form as the protobuf\n",
      " |              message :class:`~google.cloud.speech_v1.types.RecognitionConfig`\n",
      " |          audio (Union[dict, ~google.cloud.speech_v1.types.RecognitionAudio]): *Required* The audio data to be recognized.\n",
      " |              If a dict is provided, it must be of the same form as the protobuf\n",
      " |              message :class:`~google.cloud.speech_v1.types.RecognitionAudio`\n",
      " |          retry (Optional[google.api_core.retry.Retry]):  A retry object used\n",
      " |              to retry requests. If ``None`` is specified, requests will not\n",
      " |              be retried.\n",
      " |          timeout (Optional[float]): The amount of time, in seconds, to wait\n",
      " |              for the request to complete. Note that if ``retry`` is\n",
      " |              specified, the timeout applies to each individual attempt.\n",
      " |          metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n",
      " |              that is provided to the method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A :class:`~google.cloud.speech_v1.types.RecognizeResponse` instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          google.api_core.exceptions.GoogleAPICallError: If the request\n",
      " |                  failed for any reason.\n",
      " |          google.api_core.exceptions.RetryError: If the request failed due\n",
      " |                  to a retryable error and retry attempts failed.\n",
      " |          ValueError: If the parameters are invalid.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from google.cloud.speech_v1.gapic.speech_client.SpeechClient:\n",
      " |  \n",
      " |  from_service_account_file(filename, *args, **kwargs) from builtins.type\n",
      " |      Creates an instance of this client using the provided credentials\n",
      " |      file.\n",
      " |      \n",
      " |      Args:\n",
      " |          filename (str): The path to the service account private key json\n",
      " |              file.\n",
      " |          args: Additional arguments to pass to the constructor.\n",
      " |          kwargs: Additional arguments to pass to the constructor.\n",
      " |      \n",
      " |      Returns:\n",
      " |          SpeechClient: The constructed client.\n",
      " |  \n",
      " |  from_service_account_json = from_service_account_file(filename, *args, **kwargs) from builtins.type\n",
      " |      Creates an instance of this client using the provided credentials\n",
      " |      file.\n",
      " |      \n",
      " |      Args:\n",
      " |          filename (str): The path to the service account private key json\n",
      " |              file.\n",
      " |          args: Additional arguments to pass to the constructor.\n",
      " |          kwargs: Additional arguments to pass to the constructor.\n",
      " |      \n",
      " |      Returns:\n",
      " |          SpeechClient: The constructed client.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from google.cloud.speech_v1.gapic.speech_client.SpeechClient:\n",
      " |  \n",
      " |  SERVICE_ADDRESS = 'speech.googleapis.com:443'\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/files/audio.raw'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "print(dir(speech))\n",
    "print(help(speech.SpeechClient))\n",
    "#GOOGLE_APPLICATION_CREDENTIALS = \"/home/user/Desktop/IST256-edc7c4bfecba (1).json\"\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "file_name = os.path.join(\n",
    "   os.path.dirname(\"/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/Digimall-Bot\"),\n",
    "   'files',\n",
    "   'audio.raw')\n",
    "\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/john-paulbesong/Desktop/School/Semester 3/IST 256'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(\"/Users/john-paulbesong/Desktop/School/Semester 3/IST 256/Digimall-Bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function system in module posix:\n",
      "\n",
      "system(command)\n",
      "    Execute the command in a subshell.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#import module system and alias to speak\n",
    "from os import system as speak\n",
    "#example speak('say Hello world')\n",
    "#say is required and is not spoken\n",
    "print(help(speak))\n",
    "#function celsius to fahrenheit\n",
    "def celsius_to_fahrenheit(v_celcius):\n",
    "    temp_in_fahrenheit = ((9/5) * v_celcius) - 32\n",
    "    return temp_in_fahrenheit\n",
    "#function fahrenheit to celsius\n",
    "def fahrenheit_to_celsius(v_fahrenheit):\n",
    "    temp_in_celsius = ((v_fahrenheit - 32) * (5/9))\n",
    "    return temp_in_celsius\n",
    " \n",
    "#function to speak and print text\n",
    "def text_to_speech(v_text,v_print):\n",
    "    speak('say %s' % (v_text))\n",
    "    if v_print != 'n':\n",
    "        print(v_text)\n",
    " \n",
    "\n",
    "text_to_speech(v_text = 'Enter a temperature', v_print = 'n')\n",
    "temp = float(input())\n",
    "text_to_speech('The temperature is in which unit ?', 'n')\n",
    "text_to_speech('F for Farenheit or C for Celsius', 'n')\n",
    "unit = input()\n",
    "\n",
    "\n",
    "if unit == \"F\" or unit == \"f\":\n",
    "    v_converted_temp = fahrenheit_to_celsius(temp)\n",
    "    text = ('The temperature in Fahrenheit is %.2f which is %.2f in Celcius' % (temp, v_converted_temp))\n",
    " \n",
    "\n",
    "elif unit == \"C\" or unit == \"c\":\n",
    "    v_converted_temp = celsius_to_fahrenheit(temp)\n",
    "    text = ('The temperature in Celsius is %.2f which is %.2f in Fahrenheit' % (temp, v_converted_temp))\n",
    "\n",
    "\n",
    "text_to_speech(text,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
